{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deploy model to azure ml to predict Active Power for Wind Turbines at Windy Hill Wind Turbine farm\n",
    "\n",
    "This example is less about the model (arguably you could do this a number of ways) and more about a hello world example using azure ml\n",
    "\n",
    "Portions (mostly) from Azure documentation, todo includes service security"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  1.0.85\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import azureml.core\n",
    "\n",
    "# display the core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting inference_schema\n",
      "  Downloading https://files.pythonhosted.org/packages/fd/14/8a365563a28a61cbb18a41565eea27c0bacce2eac05b895efb95cb1c7d31/inference_schema-1.0.2-py3-none-any.whl\n",
      "Requirement already satisfied: pytz>=2017.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from inference_schema) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from inference_schema) (2.8.0)\n",
      "Collecting wrapt==1.11.1 (from inference_schema)\n",
      "  Downloading https://files.pythonhosted.org/packages/67/b2/0f71ca90b0ade7fad27e3d20327c996c6252a2ffe88f50a95bba7434eda9/wrapt-1.11.1.tar.gz\n",
      "Requirement already satisfied: six>=1.5 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from python-dateutil>=2.5.3->inference_schema) (1.14.0)\n",
      "Building wheels for collected packages: wrapt\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.11.1-cp36-cp36m-linux_x86_64.whl size=66554 sha256=a898d5e1501c6f8d99e39ebfb47955f39988ff2b858916fe529d520d6650d27e\n",
      "  Stored in directory: /home/azureuser/.cache/pip/wheels/89/67/41/63cbf0f6ac0a6156588b9587be4db5565f8c6d8ccef98202fc\n",
      "Successfully built wrapt\n",
      "\u001b[31mERROR: astroid 2.3.1 has requirement six==1.12, but you'll have six 1.14.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: wrapt, inference-schema\n",
      "  Found existing installation: wrapt 1.11.2\n",
      "    Uninstalling wrapt-1.11.2:\n",
      "      Successfully uninstalled wrapt-1.11.2\n",
      "Successfully installed inference-schema-1.0.2 wrapt-1.11.1\n"
     ]
    }
   ],
   "source": [
    "# package for parsing objects to/from model\n",
    "!pip install inference_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# configure environment, load model and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "model_name = \"Wind_Air_4.pkl\"\n",
    "workspace = 'turbineActivePower'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "os.stat_result(st_mode=33279, st_ino=5290, st_dev=46, st_nlink=1, st_uid=0, st_gid=0, st_size=828, st_atime=1585550695, st_mtime=1585559031, st_ctime=1585559031)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load created model that was previously created and registered\n",
    "\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.model import Model\n",
    "import os \n",
    "\n",
    "ws = Workspace.from_config()\n",
    "model=Model(ws, workspace)\n",
    "model.download(target_dir=os.getcwd(), exist_ok=True)\n",
    "\n",
    "# verify the downloaded model file\n",
    "file_path = os.path.join(os.getcwd(), model_name)\n",
    "os.stat(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LinearRegression from version 0.20.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "297.87831929324454"
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validate the model\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "# sample prediction\n",
    "new_input = [[45, 6.6]] #Temp=45 F, Wind Speed = 6.6 m/s\n",
    "poly_features = PolynomialFeatures(degree=4)\n",
    "\n",
    "loaded_model = joblib.load( os.path.join(os.getcwd(),model_name))\n",
    "output = loaded_model.predict(poly_features.fit_transform(new_input))[0]\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create scoring code - to run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import azureml.train.automl\n",
    "from sklearn.externals import joblib\n",
    "from azureml.core.model import Model\n",
    "import joblib\n",
    "\n",
    "from inference_schema.parameter_types.standard_py_parameter_type import StandardPythonParameterType\n",
    "from inference_schema.schema_decorators import input_schema, output_schema\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    # AZUREML_MODEL_DIR is an environment variable created during deployment.\n",
    "    # It is the path to the model folder (./azureml-models/$MODEL_NAME/$VERSION)\n",
    "    # For multiple models, it points to the folder containing all deployed models (./azureml-models)\n",
    "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'Wind_Air_4.pkl')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "    \n",
    "#describe input\n",
    "features = {\n",
    "    'Air Temperature': 45,\n",
    "    'Wind Speed': 6.6,\n",
    "}\n",
    "# describe output\n",
    "prediction = {\n",
    "    'Version': 1,\n",
    "    'Prediction': 297.878\n",
    "}\n",
    "\n",
    "@input_schema('param', StandardPythonParameterType(features))\n",
    "#@output_schema(StandardPythonParameterType(prediction))\n",
    "    \n",
    "def run(param):\n",
    "    try:\n",
    "        air_temp = param['Air Temperature']\n",
    "        wind_speed = param['Wind Speed']\n",
    "        # run model\n",
    "        poly_features = PolynomialFeatures(degree=4)\n",
    "        result = model.predict(poly_features.fit_transform([[air_temp,wind_speed]]))\n",
    "        # clip Active Power values - not ideal, todo: improve/resolve this(tm)\n",
    "        # cut-in speed for power generation\n",
    "        if wind_speed < 2.5: \n",
    "            prediction = 0\n",
    "        # compensating for the model, see todo above:\n",
    "        elif wind_speed > 13.25:\n",
    "            prediction = 1432\n",
    "        else:\n",
    "            prediction = result[0]\n",
    "        return {'Prediction': prediction, 'Version': 2,\"result\": result[0]}\n",
    "    except Exception as e:\n",
    "        error = str(e)\n",
    "        return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create scoring code - to run model - this time modified to use schema supported by Power BI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import azureml.train.automl\n",
    "from sklearn.externals import joblib\n",
    "from azureml.core.model import Model\n",
    "import joblib\n",
    "from inference_schema.parameter_types.pandas_parameter_type import PandasParameterType\n",
    "from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n",
    "from inference_schema.schema_decorators import input_schema, output_schema\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    # AZUREML_MODEL_DIR is an environment variable created during deployment.\n",
    "    # It is the path to the model folder (./azureml-models/$MODEL_NAME/$VERSION)\n",
    "    # For multiple models, it points to the folder containing all deployed models (./azureml-models)\n",
    "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'Wind_Air_4.pkl')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "# describe input\n",
    "features = pd.DataFrame(data=[{\n",
    "    'Air Temperature': 45.5,\n",
    "    'Wind Speed': 6.6\n",
    "}])\n",
    "\n",
    "# describe output\n",
    "active_power_prediction = np.array([297.878])\n",
    "\n",
    "@input_schema('data', PandasParameterType(features))\n",
    "@output_schema(NumpyParameterType(active_power_prediction))\n",
    "  \n",
    "def run(data):\n",
    "    output = np.empty([0])\n",
    "    try:\n",
    "        for index,row in data.iterrows():\n",
    "            # clip Active Power values - not ideal, todo: improve/resolve this(tm)\n",
    "            # cut-in speed for power generation\n",
    "            if row['Wind Speed'] < 2.5: \n",
    "                prediction = 0.0\n",
    "            # compensating for the model, see todo above:\n",
    "            elif row['Wind Speed'] > 13.25:\n",
    "                prediction = 1432.0\n",
    "            else:\n",
    "                poly_features = PolynomialFeatures(degree=4)\n",
    "                prediction = model.predict(poly_features.fit_transform([[row['Air Temperature'],row['Wind Speed']]]))[0]\n",
    "            output = np.append(output,prediction)\n",
    "        return output.tolist()\n",
    "    except Exception as e:\n",
    "        error = str(e)\n",
    "        return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the script\n",
    "%run -i score.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[298.14948763009147, 738.0379427055908]\n"
     ]
    }
   ],
   "source": [
    "# test script\n",
    "# will need to comment out @output line from score.py\n",
    "input_data = [{'Air Temperature': 45.1,'Wind Speed': 6.6},{'Air Temperature': 48,'Wind Speed': 9}]\n",
    "#input_data = [{'Air Temperature': 45.1,'Wind Speed': 6.6}]\n",
    "#Note: for production format is: input_data = {'param': {'Air Temperature': 45.1,'Wind Speed': 20}}\n",
    "data = json.dumps(input_data)\n",
    "prediction = None\n",
    "result = run(input_data)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure environment to run model and view\n",
    "\n",
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "myenv = CondaDependencies()\n",
    "myenv.add_pip_package(\"scikit-learn==0.22.1\")\n",
    "myenv.add_pip_package(\"azureml-defaults\")\n",
    "myenv.add_pip_package(\"azureml-defaults>=1.0.45\")\n",
    "myenv.add_pip_package(\"inference-schema[numpy-support]\")\n",
    "myenv.add_pip_package(\"azureml-train\")\n",
    "myenv.add_pip_package(\"azureml.train.automl\")\n",
    "myenv.add_pip_package(\"azureml-defaults\")\n",
    "myenv.add_pip_package(\"azureml-telemetry\")\n",
    "myenv.add_pip_package(\"joblib\")\n",
    "\n",
    "with open(\"myenv.yml\",\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Conda environment specification. The dependencies defined in this file will\n",
      "# be automatically provisioned for runs with userManagedDependencies=False.\n",
      "\n",
      "# Details about the Conda environment file format:\n",
      "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\n",
      "\n",
      "name: project_environment\n",
      "dependencies:\n",
      "  # The python interpreter version.\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\n",
      "- python=3.6.2\n",
      "\n",
      "- pip:\n",
      "  - scikit-learn==0.22.1\n",
      "  - inference-schema[numpy-support]\n",
      "  - azureml-train\n",
      "  - azureml.train.automl\n",
      "  - azureml-defaults\n",
      "  - azureml-telemetry\n",
      "  - joblib\n",
      "channels:\n",
      "- conda-forge\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"myenv.yml\",\"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create configuration file\n",
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n",
    "                                               memory_gb=1, \n",
    "                                               tags={\"data\": \"Wind Turbine\",  \"method\" : \"sklearn\"}, \n",
    "                                               description='Predict Wind Turbine Active Power')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running........................................................................................................................\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "CPU times: user 610 ms, sys: 73.4 ms, total: 684 ms\n",
      "Wall time: 10min 31s\n"
     ]
    }
   ],
   "source": [
    "# create service\n",
    "%%time\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.environment import Environment\n",
    "\n",
    "myenv = Environment.from_conda_specification(name=\"myenv\", file_path=\"myenv.yml\")\n",
    "inference_config = InferenceConfig(entry_script=\"score.py\", environment=myenv)\n",
    "\n",
    "service = Model.deploy(workspace=ws, \n",
    "                       name='turbine-svc', \n",
    "                       models=[model], \n",
    "                       inference_config=inference_config, \n",
    "                       deployment_config=aciconfig)\n",
    "\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running......\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "# update scoring code (only required when code changes are made)\n",
    "myenv = Environment.from_conda_specification(name=\"myenv\", file_path=\"myenv.yml\")\n",
    "inference_config = InferenceConfig(entry_script=\"score.py\", environment=myenv)\n",
    "service.update(inference_config=inference_config)\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display logs\n",
    "logs = service.get_logs()\n",
    "print(logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## swagger definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'consumes': ['application/json'],\n",
      " 'definitions': {'ErrorResponse': {'properties': {'message': {'type': 'string'},\n",
      "                                                  'status_code': {'format': 'int32',\n",
      "                                                                  'type': 'integer'}},\n",
      "                                   'type': 'object'},\n",
      "                 'ServiceInput': {'example': {'data': [{'Air Temperature': 45.5,\n",
      "                                                        'Wind Speed': 6.6}]},\n",
      "                                  'properties': {'data': {'items': {'properties': {'Air Temperature': {'format': 'double',\n",
      "                                                                                                       'type': 'number'},\n",
      "                                                                                   'Wind Speed': {'format': 'double',\n",
      "                                                                                                  'type': 'number'}},\n",
      "                                                                    'type': 'object'},\n",
      "                                                          'type': 'array'}},\n",
      "                                  'type': 'object'},\n",
      "                 'ServiceOutput': {'example': [297.878],\n",
      "                                   'items': {'format': 'double',\n",
      "                                             'type': 'number'},\n",
      "                                   'type': 'array'}},\n",
      " 'info': {'description': 'API specification for the Azure Machine Learning '\n",
      "                         'service turbine-svc',\n",
      "          'title': 'turbine-svc',\n",
      "          'version': '1.0'},\n",
      " 'paths': {'/': {'get': {'description': 'Simple health check endpoint to '\n",
      "                                        'ensure the service is up at any given '\n",
      "                                        'point.',\n",
      "                         'operationId': 'ServiceHealthCheck',\n",
      "                         'responses': {'200': {'description': 'If service is '\n",
      "                                                              'up and running, '\n",
      "                                                              'this response '\n",
      "                                                              'will be '\n",
      "                                                              'returned with '\n",
      "                                                              'the content '\n",
      "                                                              \"'Healthy'\",\n",
      "                                               'examples': {'application/json': 'Healthy'},\n",
      "                                               'schema': {'type': 'string'}},\n",
      "                                       'default': {'description': 'The service '\n",
      "                                                                  'failed to '\n",
      "                                                                  'execute due '\n",
      "                                                                  'to an '\n",
      "                                                                  'error.',\n",
      "                                                   'schema': {'$ref': '#/definitions/ErrorResponse'}}}}},\n",
      "           '/score': {'post': {'description': \"Run web service's model and get \"\n",
      "                                              'the prediction output',\n",
      "                               'operationId': 'RunMLService',\n",
      "                               'parameters': [{'description': 'The input '\n",
      "                                                              'payload for '\n",
      "                                                              'executing the '\n",
      "                                                              'real-time '\n",
      "                                                              'machine '\n",
      "                                                              'learning '\n",
      "                                                              'service.',\n",
      "                                               'in': 'body',\n",
      "                                               'name': 'serviceInputPayload',\n",
      "                                               'schema': {'$ref': '#/definitions/ServiceInput'}}],\n",
      "                               'responses': {'200': {'description': 'The '\n",
      "                                                                    'service '\n",
      "                                                                    'processed '\n",
      "                                                                    'the input '\n",
      "                                                                    'correctly '\n",
      "                                                                    'and '\n",
      "                                                                    'provided '\n",
      "                                                                    'a result '\n",
      "                                                                    'prediction, '\n",
      "                                                                    'if '\n",
      "                                                                    'applicable.',\n",
      "                                                     'schema': {'$ref': '#/definitions/ServiceOutput'}},\n",
      "                                             'default': {'description': 'The '\n",
      "                                                                        'service '\n",
      "                                                                        'failed '\n",
      "                                                                        'to '\n",
      "                                                                        'execute '\n",
      "                                                                        'due '\n",
      "                                                                        'to an '\n",
      "                                                                        'error.',\n",
      "                                                         'schema': {'$ref': '#/definitions/ErrorResponse'}}},\n",
      "                               'security': [{'Bearer': []}]}}},\n",
      " 'produces': ['application/json'],\n",
      " 'schemes': ['https'],\n",
      " 'securityDefinitions': {'Bearer': {'description': 'For example: Bearer abc123',\n",
      "                                    'in': 'header',\n",
      "                                    'name': 'Authorization',\n",
      "                                    'type': 'apiKey'}},\n",
      " 'swagger': '2.0'}\n"
     ]
    }
   ],
   "source": [
    "import pprint as pprint\n",
    "pprint.pprint(json.loads(requests.get(service.swagger_uri).text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get service URL and query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.scoring_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "prediction: [298.14948763009147, 298.14948763009147]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "input_data = {'data': [{'Air Temperature': 45.1,'Wind Speed': 6.6},{'Air Temperature': 45.1,'Wind Speed': 6.6}]}\n",
    "data = json.dumps(input_data)\n",
    "\n",
    "# for AKS deployment you'd need to the service key in the header as well\n",
    "#api_key = service.get_key()\n",
    "#headers = {'Content-Type':'application/json',  'Authorization':('Bearer '+ api_key)} \n",
    "headers = {'Content-Type':'application/json'} \n",
    "\n",
    "resp = requests.post(service.scoring_uri, data, headers=headers)\n",
    "print(resp)\n",
    "print(\"prediction:\", resp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>,[0.0]\n",
      "<Response [200]>,[0.0]\n",
      "<Response [200]>,[0.0]\n",
      "<Response [200]>,[22.953421462315305]\n",
      "<Response [200]>,[76.1170121699904]\n",
      "<Response [200]>,[137.48869821448181]\n",
      "<Response [200]>,[226.5663501563904]\n",
      "<Response [200]>,[354.10469893181187]\n",
      "<Response [200]>,[522.1153358523433]\n",
      "<Response [200]>,[723.8667126050703]\n",
      "<Response [200]>,[943.8841412525784]\n",
      "<Response [200]>,[1157.9497942329467]\n",
      "<Response [200]>,[1333.1027043597564]\n",
      "<Response [200]>,[1427.6387648220666]\n",
      "<Response [200]>,[1432.0]\n",
      "<Response [200]>,[1432.0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "headers = {'Content-Type':'application/json'} \n",
    "for wind_speed in range (0,16):\n",
    "    input_data = {'data': [{'Air Temperature': 45.1,'Wind Speed': wind_speed}]}\n",
    "    data = json.dumps(input_data)\n",
    "    resp = requests.post(service.scoring_uri, data, headers=headers)\n",
    "    print(f'{resp},{resp.text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean-up\n",
    "#service.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
